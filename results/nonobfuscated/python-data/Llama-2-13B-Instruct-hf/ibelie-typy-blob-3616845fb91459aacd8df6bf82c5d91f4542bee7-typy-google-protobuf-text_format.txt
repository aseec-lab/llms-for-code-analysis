Analyze the following piece of code: 
































__author__ = 'kenton@google.com (Kenton Varda)'

import io
import re

import six

if six.PY3:
  long = int

from typy.google.protobuf.internal import type_checkers
from typy.google.protobuf import descriptor
from typy.google.protobuf import text_encoding

__all__ = ['MessageToString', 'PrintMessage', 'PrintField',
           'PrintFieldValue', 'Merge']


_INTEGER_CHECKERS = (type_checkers.Uint32ValueChecker(),
                     type_checkers.Int32ValueChecker(),
                     type_checkers.Uint64ValueChecker(),
                     type_checkers.Int64ValueChecker())
_FLOAT_INFINITY = re.compile('-?inf(?:inity)?f?', re.IGNORECASE)
_FLOAT_NAN = re.compile('nanf?', re.IGNORECASE)
_FLOAT_TYPES = frozenset([descriptor.FieldDescriptor.CPPTYPE_FLOAT,
                          descriptor.FieldDescriptor.CPPTYPE_DOUBLE])
_QUOTES = frozenset((
))


class Error(Exception):
  



class ParseError(Error):
  



class TextWriter(object):
  def __init__(self, as_utf8):
    if six.PY2:
      self._writer = io.BytesIO()
    else:
      self._writer = io.StringIO()

  def write(self, val):
    if six.PY2:
      if isinstance(val, six.text_type):
        val = val.encode('utf-8')
    return self._writer.write(val)

  def close(self):
    return self._writer.close()

  def getvalue(self):
    return self._writer.getvalue()


def MessageToString(message, as_utf8=False, as_one_line=False,
                    pointy_brackets=False, use_index_order=False,
                    float_format=None, use_field_number=False):
  

  out = TextWriter(as_utf8)
  printer = _Printer(out, 0, as_utf8, as_one_line,
                     pointy_brackets, use_index_order, float_format,
                     use_field_number)
  printer.PrintMessage(message)
  result = out.getvalue()
  out.close()
  if as_one_line:
    return result.rstrip()
  return result


def _IsMapEntry(field):
  return (field.type == descriptor.FieldDescriptor.TYPE_MESSAGE and
          field.message_type.has_options and
          field.message_type.GetOptions().map_entry)


def PrintMessage(message, out, indent=0, as_utf8=False, as_one_line=False,
                 pointy_brackets=False, use_index_order=False,
                 float_format=None, use_field_number=False):
  printer = _Printer(out, indent, as_utf8, as_one_line,
                     pointy_brackets, use_index_order, float_format,
                     use_field_number)
  printer.PrintMessage(message)


def PrintField(field, value, out, indent=0, as_utf8=False, as_one_line=False,
               pointy_brackets=False, use_index_order=False, float_format=None):
  

  printer = _Printer(out, indent, as_utf8, as_one_line,
                     pointy_brackets, use_index_order, float_format)
  printer.PrintField(field, value)


def PrintFieldValue(field, value, out, indent=0, as_utf8=False,
                    as_one_line=False, pointy_brackets=False,
                    use_index_order=False,
                    float_format=None):
  

  printer = _Printer(out, indent, as_utf8, as_one_line,
                     pointy_brackets, use_index_order, float_format)
  printer.PrintFieldValue(field, value)


class _Printer(object):
  


  def __init__(self, out, indent=0, as_utf8=False, as_one_line=False,
               pointy_brackets=False, use_index_order=False, float_format=None,
               use_field_number=False):
    

    self.out = out
    self.indent = indent
    self.as_utf8 = as_utf8
    self.as_one_line = as_one_line
    self.pointy_brackets = pointy_brackets
    self.use_index_order = use_index_order
    self.float_format = float_format
    self.use_field_number = use_field_number

  def PrintMessage(self, message):
    

    fields = message.ListFields()
    if self.use_index_order:
      fields.sort(key=lambda x: x[0].index)
    for field, value in fields:
      if _IsMapEntry(field):
        for key in sorted(value):
          
          
          
          
          
          entry_submsg = field.message_type._concrete_class(
              key=key, value=value[key])
          self.PrintField(field, entry_submsg)
      elif field.label == descriptor.FieldDescriptor.LABEL_REPEATED:
        for element in value:
          self.PrintField(field, element)
      else:
        self.PrintField(field, value)

  def PrintField(self, field, value):
    

    out = self.out
    out.write(' ' * self.indent)
    out.write(field.name)
    if field.type == descriptor.FieldDescriptor.TYPE_MESSAGE:
      out.write('.')
      self.PrintMessage(value)
    elif field.type == descriptor.FieldDescriptor.TYPE_INT32:
      out.write(' %d' % value)
    elif field.type == descriptor.FieldDescriptor.TYPE_INT64:
      out.write(' %ld' % value)
    elif field.type == descriptor.FieldDescriptor.TYPE_UINT32:
      out.write(' %u' % value)
    elif field.type == descriptor.FieldDescriptor.TYPE_UINT64:
      out.write(' %lu' % value)
    elif field.type == descriptor.FieldDescriptor.TYPE_FLOAT:
      out.write(' %g' % value)
    elif field.type == descriptor.FieldDescriptor.TYPE_DOUBLE:
      out.write(' %g' % value)
    elif field.type == descriptor.FieldDescriptor.TYPE_BOOL:
      out.write(' %s' % str(value).lower())
    elif field.type == descriptor.FieldDescriptor.TYPE_STRING:
      out.write(' "%s"' % value)
    elif field.type == descriptor.FieldDescriptor.TYPE_GROUP:
      out.write(' (')
      self.PrintMessage(value)
      out.write(')')
    elif field.type == descriptor.FieldDescriptor.TYPE_ONEOF:
      out.write(' %s' % field.oneof_name)
    else:
      raise NotImplementedError('Field type %s not implemented' % field.type)
    out.write('\n')
    self.indent += 1

  def PrintFieldValue(self, field, value):
    

    out = self.out
    out.write(' ' * self.indent)
    out.write(field.name)
    if value is not None:
      out.write(':')
      if field.type == descriptor.FieldDescriptor.TYPE_MESSAGE:
        self.PrintMessage(value)
      elif field.type == descriptor.FieldDescriptor.TYPE_INT32:
        out.write(' %d' % value)
      elif field.type == descriptor.FieldDescriptor.TYPE_INT64:
        out.write(' %ld' % value)
      elif field.type == descriptor.FieldDescriptor.TYPE_UINT32:
        out.write(' %u' % value)
      elif field.type == descriptor.FieldDescriptor.TYPE_UINT64:
        out.write(' %lu' % value)
      elif field.type == descriptor.FieldDescriptor.TYPE_FLOAT:
        out.write(' %g' % value)
      elif field.type == descriptor.FieldDescriptor.TYPE_DOUBLE:
        out.write(' %g' % value)
      elif field.type == descriptor.FieldDescriptor.TYPE_BOOL:
        out.write(' %s' % str(value).lower())
      elif field.type == descriptor.FieldDescriptor.TYPE_STRING:
        out.write(' "% Analyze the following piece of code: )
    if self.use_field_number:
      out.write(str(field.number))
    else:
      if field.is_extension:
        out.write('[')
        if (field.containing_type.GetOptions().message_set_wire_format and
            field.type == descriptor.FieldDescriptor.TYPE_MESSAGE and
            field.label == descriptor.FieldDescriptor.LABEL_OPTIONAL):
          out.write(field.message_type.full_name)
        else:
          out.write(field.full_name)
        out.write(']')
      elif field.type == descriptor.FieldDescriptor.TYPE_GROUP:
        
        out.write(field.message_type.name)
      else:
        out.write(field.name)

    if field.cpp_type != descriptor.FieldDescriptor.CPPTYPE_MESSAGE:
      
      
      out.write(': ')

    self.PrintFieldValue(field, value)
    if self.as_one_line:
      out.write(' ')
    else:
      out.write('\n')

  def PrintFieldValue(self, field, value):
    

    out = self.out
    if self.pointy_brackets:
      openb = '<'
      closeb = '>'
    else:
      openb = '{'
      closeb = '}'

    if field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE:
      if self.as_one_line:
        out.write(' %s ' % openb)
        self.PrintMessage(value)
        out.write(closeb)
      else:
        out.write(' %s\n' % openb)
        self.indent += 2
        self.PrintMessage(value)
        self.indent -= 2
        out.write(' ' * self.indent + closeb)
    elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_ENUM:
      enum_value = field.enum_type.values_by_number.get(value, None)
      if enum_value is not None:
        out.write(enum_value.name)
      else:
        out.write(str(value))
    elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_STRING:
      out.write('\"')
      if isinstance(value, six.text_type):
        out_value = value.encode('utf-8')
      else:
        out_value = value
      if field.type == descriptor.FieldDescriptor.TYPE_BYTES:
        
        out_as_utf8 = False
      else:
        out_as_utf8 = self.as_utf8
      out.write(text_encoding.CEscape(out_value, out_as_utf8))
      out.write('\"')
    elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_BOOL:
      if value:
        out.write('true')
      else:
        out.write('false')
    elif field.cpp_type in _FLOAT_TYPES and self.float_format is not None:
      out.write('{1:{0}}'.format(self.float_format, value))
    else:
      out.write(str(value))


def Parse(text, message,
          allow_unknown_extension=False, allow_field_number=False):
  

  if not isinstance(text, str):
    text = text.decode('utf-8')
  return ParseLines(text.split('\n'), message, allow_unknown_extension,
                    allow_field_number)


def Merge(text, message, allow_unknown_extension=False,
          allow_field_number=False):
  

  return MergeLines(text.split('\n'), message, allow_unknown_extension,
                    allow_field_number)


def ParseLines(lines, message, allow_unknown_extension=False,
               allow_field_number=False):
  

  parser = _Parser(allow_unknown_extension, allow_field_number)
  return parser.ParseLines(lines, message)


def MergeLines(lines, message, allow_unknown_extension=False,
               allow_field_number=False):
  

  parser = _Parser(allow_unknown_extension, allow_field_number)
  return parser.MergeLines(lines, message)


class _Parser(object):
  


  def __init__(self, allow_unknown_extension=False, allow_field_number=False):
    self.allow_unknown_extension = allow_unknown_extension
    self.allow_field_number = allow_field_number

  def ParseFromString(self, text, message):
    

    if not isinstance(text, str):
      text = text.decode('utf-8')
    return self.ParseLines(text.split('\n'), message)

  def ParseLines(self, lines, message):
    

    self._allow_multiple_scalars = False
    self._ParseOrMerge(lines, message)
    return message

  def MergeFromString(self, text, message):
    

    return self._MergeLines(text.split('\n'), message)

  def MergeLines(self, lines, message):
    

    self._allow_multiple_scalars = True
    self._ParseOrMerge(lines, message)
    return message

  def _ParseOrMerge(self, lines, message):
    

    tokenizer = _Tokenizer(lines)
    while not tokenizer.AtEnd():
      self._MergeField(tokenizer, message)

  def _MergeField(self, tokenizer, message):
    

    message_descriptor = message.DESCRIPTOR
    if (hasattr(message_descriptor, 'syntax') and
        message_descriptor.syntax == 'proto3'):
      
      
      self._allow_multiple_scalars = True
    if tokenizer.TryConsume('['):
      name = [tokenizer.ConsumeIdentifier()]
      while tokenizer.TryConsume('.'):
        name.append(tokenizer.ConsumeIdentifier())
      self._MergeFieldValue(tokenizer, message, name)
    else:
      self._MergeFieldValue(tokenizer, message, None)

  def _MergeFieldValue(self, tokenizer, message, name):
    

    field_descriptor = message.DESCRIPTOR.fields_by_name[name]
    if field_descriptor.type == descriptor.FieldDescriptor.TYPE_MESSAGE:
      if self.allow_unknown_extension:
        self._MergeMessage(tokenizer, message, field_descriptor)
      else:
        raise _ParseError('extension', field_descriptor.name)
    elif field_descriptor.type == descriptor.FieldDescriptor.TYPE_GROUP:
      self._MergeGroup(tokenizer, message, field_descriptor)
    else:
      self._MergeScalar(tokenizer, message, field_descriptor)

  def _MergeMessage(self, tokenizer, message, field_descriptor):
    

    nested_message = message.DESCRIPTOR.fields_by_name[field_descriptor.name].message_type
    if nested_message is None:
      raise _ParseError('message', field_descriptor.name)
    return self.MergeFromString(tokenizer.ConsumeAll(), nested_message)

  def _MergeGroup(self, tokenizer, message, field_descriptor):
    

    nested_message = message.DESCRIPTOR.fields_by_name[field_descriptor.name].message_type
    if nested_message is None:
      raise _ParseError('group', field_descriptor.name)
    return self.MergeFromString(tokenizer.ConsumeAll(), nested_message)

  def _MergeScalar(self, tokenizer, message, field_descriptor):
    

    value = tokenizer.ConsumeScalar()
    field_type = field_descriptor.type
    if field_type in _FLOAT_TYPES:
      value = float(value)
    elif field_type == descriptor.FieldDescriptor.TYPE_BOOL:
      value = bool(value)
    elif field_type == descriptor.FieldDescriptor.TYPE_ENUM:
      value = field_descriptor.enum_type.values_by_number.get(value, None)
      if value is None:
        raise _ParseError('enum', field_descriptor.name)
    elif field_type == descriptor.FieldDescriptor.TYPE_STRING:
      value = text_encoding.Decode(value, 'utf-8')
    message.AddField(field_descriptor.name, value)

  def _ParseError(self, tokenizer, message, field_descriptor, expected_type=None):
    

    if expected_type is None:
      expected_type = field_descriptor.type
    raise _ParseError('%s %s' % (tokenizer.token, field_descriptor.name),
                      expected_type)


class _Tokenizer(object):
  


  def __init__(self, lines):
    self.lines = lines
    self.token Analyze the following piece of code: izer.ConsumeIdentifier())
      name = '.'.join(name)

      if not message_descriptor.is_extendable:
        raise tokenizer.ParseErrorPreviousToken(
            'Message type "%s" does not have extensions.' %
            message_descriptor.full_name)
      
      field = message.Extensions._FindExtensionByName(name)
      
      if not field:
        if self.allow_unknown_extension:
          field = None
        else:
          raise tokenizer.ParseErrorPreviousToken(
              'Extension "%s" not registered.' % name)
      elif message_descriptor != field.containing_type:
        raise tokenizer.ParseErrorPreviousToken(
            'Extension "%s" does not extend message type "%s".' % (
                name, message_descriptor.full_name))

      tokenizer.Consume(']')

    else:
      name = tokenizer.ConsumeIdentifier()
      if self.allow_field_number and name.isdigit():
        number = ParseInteger(name, True, True)
        field = message_descriptor.fields_by_number.get(number, None)
        if not field and message_descriptor.is_extendable:
          field = message.Extensions._FindExtensionByNumber(number)
      else:
        field = message_descriptor.fields_by_name.get(name, None)

        
        
        
        if not field:
          field = message_descriptor.fields_by_name.get(name.lower(), None)
          if field and field.type != descriptor.FieldDescriptor.TYPE_GROUP:
            field = None

        if (field and field.type == descriptor.FieldDescriptor.TYPE_GROUP and
            field.message_type.name != name):
          field = None

      if not field:
        raise tokenizer.ParseErrorPreviousToken(
            'Message type "%s" has no field named "%s".' % (
                message_descriptor.full_name, name))

    if field:
      if not self._allow_multiple_scalars and field.containing_oneof:
        
        
        
        which_oneof = message.WhichOneof(field.containing_oneof.name)
        if which_oneof is not None and which_oneof != field.name:
          raise tokenizer.ParseErrorPreviousToken(
              'Field "%s" is specified along with field "%s", another member '
              'of oneof "%s" for message type "%s".' % (
                  field.name, which_oneof, field.containing_oneof.name,
                  message_descriptor.full_name))

      if field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE:
        tokenizer.TryConsume(':')
        merger = self._MergeMessageField
      else:
        tokenizer.Consume(':')
        merger = self._MergeScalarField

      if (field.label == descriptor.FieldDescriptor.LABEL_REPEATED
          and tokenizer.TryConsume('[')):
        
        while True:
          merger(tokenizer, message, field)
          if tokenizer.TryConsume(']'): break
          tokenizer.Consume(',')

      else:
        merger(tokenizer, message, field)

    else:  
      assert self.allow_unknown_extension
      _SkipFieldContents(tokenizer)

    
    
    if not tokenizer.TryConsume(','):
      tokenizer.TryConsume(';')

  def _MergeMessageField(self, tokenizer, message, field):
    

    is_map_entry = _IsMapEntry(field)

    if tokenizer.TryConsume('<'):
      end_token = '>'
    else:
      tokenizer.Consume('{')
      end_token = '}'

    if field.label == descriptor.FieldDescriptor.LABEL_REPEATED:
      if field.is_extension:
        sub_message = message.Extensions[field].add()
      elif is_map_entry:
        
        sub_message = field.message_type._concrete_class()
      else:
        sub_message = getattr(message, field.name).add()
    else:
      if field.is_extension:
        sub_message = message.Extensions[field]
      else:
        sub_message = getattr(message, field.name)
      sub_message.SetInParent()

    while not tokenizer.TryConsume(end_token):
      if tokenizer.AtEnd():
        raise tokenizer.ParseErrorPreviousToken('Expected "%s".' % (end_token,))
      self._MergeField(tokenizer, sub_message)

    if is_map_entry:
      value_cpptype = field.message_type.fields_by_name['value'].cpp_type
      if value_cpptype == descriptor.FieldDescriptor.CPPTYPE_MESSAGE:
        value = getattr(message, field.name)[sub_message.key]
        value.MergeFrom(sub_message.value)
      else:
        getattr(message, field.name)[sub_message.key] = sub_message.value

  def _MergeScalarField(self, tokenizer, message, field):
    

    _ = self.allow_unknown_extension
    value = None

    if field.type in (descriptor.FieldDescriptor.TYPE_INT32,
                      descriptor.FieldDescriptor.TYPE_SINT32,
                      descriptor.FieldDescriptor.TYPE_SFIXED32):
      value = tokenizer.ConsumeInt32()
    elif field.type in (descriptor.FieldDescriptor.TYPE_INT64,
                        descriptor.FieldDescriptor.TYPE_SINT64,
                        descriptor.FieldDescriptor.TYPE_SFIXED64):
      value = tokenizer.ConsumeInt64()
    elif field.type in (descriptor.FieldDescriptor.TYPE_UINT32,
                        descriptor.FieldDescriptor.TYPE_FIXED32):
      value = tokenizer.ConsumeUint32()
    elif field.type in (descriptor.FieldDescriptor.TYPE_UINT64,
                        descriptor.FieldDescriptor.TYPE_FIXED64):
      value = tokenizer.ConsumeUint64()
    elif field.type == descriptor.FieldDescriptor.TYPE_DOUBLE:
      value = tokenizer.ConsumeDouble()
    elif field.type == descriptor.FieldDescriptor.TYPE_GROUP:
      value = message.Extensions[field]
    else:
      raise NotImplementedError

    if field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE:
      if value is not None:
        value.MergeFrom(field.message_type)

    setattr(message, field.name, value)



  def _SkipFieldContents(self, tokenizer):
    

    _ = self.allow_unknown_extension
    while tokenizer.TryConsume(','):
      pass
    tokenizer.Consume(';')




class _MessageType(object):
  def __init__(self, descriptor, allow_unknown_extension=False):
    self.descriptor = descriptor
    self.allow_unknown_extension = allow_unknown_extension





  def __enter__(self):
    return self





  def __exit__(self, type, value, traceback):
    pass





  def _MergeField(self, tokenizer, message):
    

    field_descriptor = self.descriptor.fields_by_name[tokenizer.ConsumeIdentifier()]
    if field_descriptor.type == descriptor.FieldDescriptor.TYPE_GROUP:
      message.Extensions[field_descriptor] = message.Extensions[field_descriptor].add()
    else:
      setattr(message, field_descriptor.name, tokenizer.ConsumeScalar())





  def _MergeMessageField(self, tokenizer, message):
    

    field_descriptor = self.descriptor.fields_by_name[tokenizer.ConsumeIdentifier()]
    if field_descriptor.type == descriptor.FieldDescriptor.TYPE_GROUP:
      sub_message = message.Extensions[field_descriptor]
      while not tokenizer.TryConsume('>'):
        self._MergeField(tokenizer, sub_message)
        if tokenizer.TryConsume(','):
          pass
        else:
          break
      tokenizer.Consume('>')
    else:
      self._MergeField(tokenizer, message)





  def _MergeScalarField(self, tokenizer, message):
    

    field_descriptor = self.descriptor.fields_by_name[tokenizer.ConsumeIdentifier()]
    if field_descriptor.type in (descriptor.FieldDescriptor.TYPE_INT32,
                                descriptor.FieldDescriptor.TYPE_SINT32,
                                descriptor.FieldDescriptor.TYPE_SFIXED32):
      value = tokenizer.ConsumeInt32()
    elif field_descriptor.type in (descriptor.FieldDescriptor.TYPE_INT64,
                                 descriptor.FieldDescriptor Analyze the following piece of code: Descriptor.TYPE_UINT64,
                        descriptor.FieldDescriptor.TYPE_FIXED64):
      value = tokenizer.ConsumeUint64()
    elif field.type in (descriptor.FieldDescriptor.TYPE_FLOAT,
                        descriptor.FieldDescriptor.TYPE_DOUBLE):
      value = tokenizer.ConsumeFloat()
    elif field.type == descriptor.FieldDescriptor.TYPE_BOOL:
      value = tokenizer.ConsumeBool()
    elif field.type == descriptor.FieldDescriptor.TYPE_STRING:
      value = tokenizer.ConsumeString()
    elif field.type == descriptor.FieldDescriptor.TYPE_BYTES:
      value = tokenizer.ConsumeByteString()
    elif field.type == descriptor.FieldDescriptor.TYPE_ENUM:
      value = tokenizer.ConsumeEnum(field)
    else:
      raise RuntimeError('Unknown field type %d' % field.type)

    if field.label == descriptor.FieldDescriptor.LABEL_REPEATED:
      if field.is_extension:
        message.Extensions[field].append(value)
      else:
        getattr(message, field.name).append(value)
    else:
      if field.is_extension:
        if not self._allow_multiple_scalars and message.HasExtension(field):
          raise tokenizer.ParseErrorPreviousToken(
              'Message type "%s" should not have multiple "%s" extensions.' %
              (message.DESCRIPTOR.full_name, field.full_name))
        else:
          message.Extensions[field] = value
      else:
        if not self._allow_multiple_scalars and message.HasField(field.name):
          raise tokenizer.ParseErrorPreviousToken(
              'Message type "%s" should not have multiple "%s" fields.' %
              (message.DESCRIPTOR.full_name, field.name))
        else:
          setattr(message, field.name, value)


def _SkipFieldContents(tokenizer):
  

  
  
  
  
  
  
  if tokenizer.TryConsume(':') and not tokenizer.LookingAt(
      '{') and not tokenizer.LookingAt('<'):
    _SkipFieldValue(tokenizer)
  else:
    _SkipFieldMessage(tokenizer)


def _SkipField(tokenizer):
  

  if tokenizer.TryConsume('['):
    
    tokenizer.ConsumeIdentifier()
    while tokenizer.TryConsume('.'):
      tokenizer.ConsumeIdentifier()
    tokenizer.Consume(']')
  else:
    tokenizer.ConsumeIdentifier()

  _SkipFieldContents(tokenizer)

  
  
  if not tokenizer.TryConsume(','):
    tokenizer.TryConsume(';')


def _SkipFieldMessage(tokenizer):
  


  if tokenizer.TryConsume('<'):
    delimiter = '>'
  else:
    tokenizer.Consume('{')
    delimiter = '}'

  while not tokenizer.LookingAt('>') and not tokenizer.LookingAt('}'):
    _SkipField(tokenizer)

  tokenizer.Consume(delimiter)


def _SkipFieldValue(tokenizer):
  

  
  
  if tokenizer.TryConsumeByteString():
    while tokenizer.TryConsumeByteString():
      pass
    return

  if (not tokenizer.TryConsumeIdentifier() and
      not tokenizer.TryConsumeInt64() and
      not tokenizer.TryConsumeUint64() and
      not tokenizer.TryConsumeFloat()):
    raise ParseError('Invalid field value: ' + tokenizer.token)


class _Tokenizer(object):
  


  _WHITESPACE = re.compile('(\\s|(
  _TOKEN = re.compile('|'.join([
      r'[a-zA-Z_][0-9a-zA-Z_+-]*',             
      r'([0-9+-]|(\.[0-9]))[0-9a-zA-Z_.+-]*',  
  ] + [                                        
      r'{qt}([^{qt}\n\\]|\\.)*({qt}|\\?$)'.format(qt=mark) for mark in _QUOTES
  ]))

  _IDENTIFIER = re.compile(r'\w+')

  def __init__(self, lines):
    self._position = 0
    self._line = -1
    self._column = 0
    self._token_start = None
    self.token = ''
    self._lines = iter(lines)
    self._current_line = ''
    self._previous_line = 0
    self._previous_column = 0
    self._more_lines = True
    self._SkipWhitespace()
    self.NextToken()

  def LookingAt(self, token):
    return self.token == token

  def AtEnd(self):
    

    return not self.token

  def _PopLine(self):
    while len(self._current_line) <= self._column:
      try:
        self._current_line = next(self._lines)
      except StopIteration:
        self._current_line = ''
        self._more_lines = False
        return
      else:
        self._line += 1
        self._column = 0

  def _SkipWhitespace(self):
    while True:
      self._PopLine()
      match = self._WHITESPACE.match(self._current_line, self._column)
      if not match:
        break
      length = len(match.group(0))
      self._column += length

  def TryConsume(self, token):
    

    if self.token == token:
      self.NextToken()
      return True
    return False

  def Consume(self, token):
    

    if not self.TryConsume(token):
      raise self._ParseError('Expected "%s".' % token)

  def TryConsumeIdentifier(self):
    

    if self.LookingAt(self._IDENTIFIER):
      return True
    return False

  def ConsumeIdentifier(self):
    

    if not self.TryConsumeIdentifier():
      raise self._ParseError('Expected identifier.')

  def NextToken(self):
    

    if self.AtEnd():
      return
    self._PopLine()
    self._SkipWhitespace()
    self.token = self._current_line[self._column:]
    self._column = len(self.token)
    return self.token

  def ParseError(self, message):
    

    self._more_lines = False
    raise self._ParseError(message)

  def _ParseError(self, message):
    

    self._more_lines = False
    raise ParseError(message)


class _Message(object):
  


  def __init__(self, descriptor, tokenizer):
    self.DESCRIPTOR = descriptor
    self.fields = []
    self.Extensions = {}
    self.is_extension = False
    self.AllowMultipleScalars = False
    self.tokenizer = tokenizer

  def AddExtension(self, field):
    

    if self.is_extension:
      raise RuntimeError('Message type %s already has an extension.' % self.DESCRIPTOR.full_name)
    self.is_extension = True
    self.Extensions[field] = []

  def Extension(self, field):
    

    if field not in self.Extensions:
      raise RuntimeError('Extension %s not found.' % field)
    return self.Extensions[field]

  def Field(self, field):
    

    if field not in self.fields:
      raise RuntimeError('Field %s not found.' % field)
    return self.fields[field]

  def HasField(self, field):
    

    return field in self.fields

  def HasExtension(self, field):
    

    return field in self.Extensions

  def ClearExtensions(self):
    

    self.is_extension = False
    self.Extensions = {}


class _Parser(object):
  


  def __init__(self, descriptor, tokenizer):
    self.descriptor = descriptor
    self.tokenizer = tokenizer
    self.message = None

  def Parse(self):
    

    try:
      self.message = _Message(self.descriptor, self.tokenizer)
      self.tokenizer.NextToken()
      self.message.Parse(self.tokenizer)
      return self.message
    except ParseError as e:
      raise ParseError('%s' % e)

  def ParseMessage(self):
    

    try:
      self.message = _Message(self.descriptor, self.tokenizer)
      self.tokenizer.NextToken()
      self.message.ParseMessage(self.tokenizer)
      return self.message
    except ParseError as e:
      raise ParseError('%s' % e)

  def ParseExtensions( Analyze the following piece of code: self):
    try:
      self.ConsumeIdentifier()
      return True
    except ParseError:
      return False

  def ConsumeIdentifier(self):
    

    result = self.token
    if not self._IDENTIFIER.match(result):
      raise self._ParseError('Expected identifier.')
    self.NextToken()
    return result

  def ConsumeInt32(self):
    

    try:
      result = ParseInteger(self.token, is_signed=True, is_long=False)
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result

  def ConsumeUint32(self):
    

    try:
      result = ParseInteger(self.token, is_signed=False, is_long=False)
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result

  def TryConsumeInt64(self):
    try:
      self.ConsumeInt64()
      return True
    except ParseError:
      return False

  def ConsumeInt64(self):
    

    try:
      result = ParseInteger(self.token, is_signed=True, is_long=True)
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result

  def TryConsumeUint64(self):
    try:
      self.ConsumeUint64()
      return True
    except ParseError:
      return False

  def ConsumeUint64(self):
    

    try:
      result = ParseInteger(self.token, is_signed=False, is_long=True)
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result

  def TryConsumeFloat(self):
    try:
      self.ConsumeFloat()
      return True
    except ParseError:
      return False

  def ConsumeFloat(self):
    

    try:
      result = ParseFloat(self.token)
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result

  def ConsumeBool(self):
    

    try:
      result = ParseBool(self.token)
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result

  def TryConsumeByteString(self):
    try:
      self.ConsumeByteString()
      return True
    except ParseError:
      return False

  def ConsumeString(self):
    

    the_bytes = self.ConsumeByteString()
    try:
      return six.text_type(the_bytes, 'utf-8')
    except UnicodeDecodeError as e:
      raise self._StringParseError(e)

  def ConsumeByteString(self):
    

    the_list = [self._ConsumeSingleByteString()]
    while self.token and self.token[0] in _QUOTES:
      the_list.append(self._ConsumeSingleByteString())
    return b''.join(the_list)

  def _ConsumeSingleByteString(self):
    

    text = self.token
    if len(text) < 1 or text[0] not in _QUOTES:
      raise self._ParseError('Expected string but found: %r' % (text,))

    if len(text) < 2 or text[-1] != text[0]:
      raise self._ParseError('String missing ending quote: %r' % (text,))

    try:
      result = text_encoding.CUnescape(text[1:-1])
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result

  def ConsumeEnum(self, field):
    try:
      result = ParseEnum(field, self.token)
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result

  def ParseErrorPreviousToken(self, message):
    

    return ParseError('%d:%d : %s' % (
        self._previous_line + 1, self._previous_column + 1, message))

  def _ParseError(self, message):
    

    return ParseError('%d:%d : %s' % (
        self._line + 1, self._column + 1, message))

  def _StringParseError(self, e):
    return self._ParseError('Couldn\'t parse string: ' + str(e))

  def NextToken(self):
    

    self._previous_line = self._line
    self._previous_column = self._column

    self._column += len(self.token)
    self._SkipWhitespace()

    if not self._more_lines:
      self.token = ''
      return

    match = self._TOKEN.match(self._current_line, self._column)
    if match:
      token = match.group(0)
      self.token = token
    else:
      self.token = self._current_line[self._column]


def ParseInteger(text, is_signed=False, is_long=False):
  

  
  try:
    
    
    
    if is_long:
      result = long(text, 0)
    else:
      result = int(text, 0)
  except ValueError:
    raise ValueError('Couldn\'t parse integer: %s' % text)

  
  checker = _INTEGER_CHECKERS[2 * int(is_long) + int(is_signed)]
  checker.CheckValue(result)
  return result


def ParseFloat(text):
  

  try:
    
    return float(text)
  except ValueError:
    
    if _FLOAT_INFINITY.match(text):
      return _FLOAT_INFINITY_MATCH
    elif _FLOAT_NAN.match(text):
      return _FLOAT_NAN_MATCH
    else:
      raise ValueError('Couldn\'t parse float: %s' % text)


def ParseBool(text):
  

  if text.lower() in _BOOLEAN_TRUE_VALUES:
    return True
  elif text.lower() in _BOOLEAN_FALSE_VALUES:
    return False
  else:
    raise ValueError('Couldn\'t parse bool: %s' % text)


def ParseEnum(field, text):
  

  try:
    
    return field.parse(text)
  except ValueError:
    raise ValueError('Couldn\'t parse enum: %s' % text)


def _SkipWhitespace():
    

    while self._current_line and self._current_line[0].isspace():
      self._line += 1
      self._column = 0
      self._SkipLine()


def _SkipLine():
    

    self._current_line = self.stream.readline()
    self._column = 0
    if not self._current_line:
      self._more_lines = False


def _ConsumeSingleQuoteString():
    

    text = self.token
    if len(text) < 1 or text[0] not in _SINGLE_QUOTE:
      raise self._ParseError('Expected single quote string but found: %r' % (text,))

    if len(text) < 2 or text[-1] != text[0]:
      raise self._ParseError('String missing ending quote: %r' % (text,))

    try:
      result = text_encoding.CUnescape(text[1:-1])
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result


def _ConsumeDoubleQuoteString():
    

    text = self.token
    if len(text) < 1 or text[0] not in _DOUBLE_QUOTE:
      raise self._ParseError('Expected double quote string but found: %r' % (text,))

    if len(text) < 2 or text[-1] != text[0]:
      raise self._ParseError('String missing ending quote: %r' % (text,))

    try:
      result = text_encoding.CUnescape(text[1:-1])
    except ValueError as e:
      raise self._ParseError(str(e))
    self.NextToken()
    return result


def _ConsumeRegex():
    

    text = self.token
    if len(text) < 1 or text[0] not in _REGEX_CHARS:
      raise self._ParseError('Expected regex but found: %r' % (text,))

    try:
      result = re.compile(text)
    except ValueError as e:
      raise self._ParseError(str(e))
 Analyze the following piece of code:      if text[0] == '-':
        return float('-inf')
      else:
        return float('inf')
    elif _FLOAT_NAN.match(text):
      return float('nan')
    else:
      
      try:
        return float(text.rstrip('f'))
      except ValueError:
        raise ValueError('Couldn\'t parse float: %s' % text)


def ParseBool(text):
  

  if text in ('true', 't', '1'):
    return True
  elif text in ('false', 'f', '0'):
    return False
  else:
    raise ValueError('Expected "true" or "false".')


def ParseEnum(field, value):
  

  enum_descriptor = field.enum_type
  try:
    number = int(value, 0)
  except ValueError:
    
    enum_value = enum_descriptor.values_by_name.get(value, None)
    if enum_value is None:
      raise ValueError(
          'Enum type "%s" has no value named %s.' % (
              enum_descriptor.full_name, value))
  else:
    
    enum_value = enum_descriptor.values_by_number.get(number, None)
    if enum_value is None:
      raise ValueError(
          'Enum type "%s" has no value with number %d.' % (
              enum_descriptor.full_name, number))
  return enum_value.number


def ParseDuration(text):
  

  if text in ('infinity', '-infinity'):
    return timedelta(infinite=True)
  elif text in ('nanoseconds', 'ns'):
    return timedelta(nanoseconds=1)
  elif text in ('microseconds', 'us'):
    return timedelta(microseconds=1)
  elif text in ('milliseconds', 'ms'):
    return timedelta(milliseconds=1)
  elif text in ('seconds', 's'):
    return timedelta(seconds=1)
  elif text in ('minutes', 'm'):
    return timedelta(minutes=1)
  elif text in ('hours', 'h'):
    return timedelta(hours=1)
  elif text in ('days', 'd'):
    return timedelta(days=1)
  else:
    try:
      return timedelta(total_seconds=int(text))
    except ValueError:
      raise ValueError('Could not parse duration: %s' % text)


def ParseTime(text):
  

  if text in ('infinity', '-infinity'):
    return datetime.timedelta(infinite=True)
  elif text in ('nanoseconds', 'ns'):
    return datetime.timedelta(nanoseconds=1)
  elif text in ('microseconds', 'us'):
    return datetime.timedelta(microseconds=1)
  elif text in ('milliseconds', 'ms'):
    return datetime.timedelta(milliseconds=1)
  elif text in ('seconds', 's'):
    return datetime.timedelta(seconds=1)
  elif text in ('minutes', 'm'):
    return datetime.timedelta(minutes=1)
  elif text in ('hours', 'h'):
    return datetime.timedelta(hours=1)
  elif text in ('days', 'd'):
    return datetime.timedelta(days=1)
  else:
    try:
      return datetime.timedelta(total_seconds=int(text))
    except ValueError:
      raise ValueError('Could not parse time: %s' % text)


def ParseDate(text):
  

  if text in ('infinity', '-infinity'):
    return datetime.date.min
  elif text in ('nanoseconds', 'ns'):
    return datetime.date.from timedelta(nanoseconds=1)
  elif text in ('microseconds', 'us'):
    return datetime.date.from timedelta(microseconds=1)
  elif text in ('milliseconds', 'ms'):
    return datetime.date.from timedelta(milliseconds=1)
  elif text in ('seconds', 's'):
    return datetime.date.from timedelta(seconds=1)
  elif text in ('minutes', 'm'):
    return datetime.date.from timedelta(minutes=1)
  elif text in ('hours', 'h'):
    return datetime.date.from timedelta(hours=1)
  elif text in ('days', 'd